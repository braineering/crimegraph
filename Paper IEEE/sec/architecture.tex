\section{Architecture}
\label{sec:architecture}

An application for the analysis of evolving criminal networks requires the real-time processing of heterogeneous data from multiple distributed sources.

%In an widely extended criminal scenario, the amount of data is huge, heterogeneous and generated rapidly. 
In order to extract valuable information from such data sources, the systems must be highly scalable, provide high throughput and convenient exploration of results.
%: a large number of people, criminals, devices, and sensors are connected via digital networks, and their interactions generate enormous valuable information \cite{FrameworkBigdata}. For these reasons, we are interested to an high-throughput and scalable process of analysis.
%Furthermore, application usage as a tool to support the law enforcement agencies, it requires the storage capacity of the social network in a database that can be consulted rapidly.

Considering these requirements, we propose an application that follows the \textit{data stream processing} (DSP) approach. A DSP application is modelled as a graph of connected operators, where each one implements a task to be executed on-the-fly on continuous streams of data.

Our application provides an extremely flexible architecture, making it really easy to deploy and evaluate performances of any metric.
It provides high scalability and throughput leveraging (i) decoupling between data injection, data processing and storage, (ii) distribution of stateless DSP operators, (iii) adoption of a high-scalable publish/subscribe system (iv) adoption of a high-throughput DSP framework and (v) graph-based storage system providing high-scalability for read-intensive tasks.
The data stream processing architecture is implemented with \textit{Apache Flink}, a highly scalable DSP framework notable for its throughput maximisation.
Data injection is provided by \textit{Apache Kafka}, a widely adopted pub/sub system natively thought to implement asynchronous communication in big data analytics applications.
Criminal network graph is stored in \textit{Neo4j}, a highly scalable graph database that optimises the storage of large graphs and provides a convenient web-based data exploration tool.

In Figure~\ref{fig:topology} we represent the architecture of the proposed system, with a focus on the topology of stream operators. Data coming from heterogeneous sources are injected into the system with Kafka. The \texttt{GraphUpdate} operator records the received interactions into Neo4j, determining the consequently fired mandatory updates. The \texttt{ScoreCalculator} operator computes the deployed metrics retrieving from Neo4j the required features of the criminal network. The links with the score previously computed are then split into hidden and potential links, which are then filter with the thresholding process. The evolving graph made of real and mined links can be visualised and explored with the Neo4J Web Browser.

\begin{figure*}
\centering
\includegraphics[width=6in]{./fig/topology}
\caption{The architecture.}
\label{fig:topology}
\end{figure*}

