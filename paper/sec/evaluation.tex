\section{Evaluation}
\label{sec:evaluation}

Two commonly used indices are adopted to measure the accuracy of link mining algorithms: \textit{AUC} and  \textit{Precision} \cite{Lu2011}. We focused here on AUC because it is stronger in revealing false positivity issues.
%
To apply those indices, the original dataset is partitioned into a training set and a test set, according to some given test ratio $\alpha$. 
%
Formally, given two instants $t_{0}$ and $t_{1}$ with $t_{0} < t_{1}$, we denote $G[t_{0},t_{1}]$ the subgraph of G consisting of all edges created within time interval $[t_{0},t_{1}]$. Identified three times: $t_{0}, t_{1}, t_{2}$, with $t_{0}<t_{1}<t_{2}$, we refer to $[t_{0},t_{1}]$ as the \textit{training interval} and $[t_{1},t_{2}]$ as the \textit{test interval}. For example, applying a \textit{prediction algorithm} on the graph obtained after the training interval, as $G[t_{0},t_{1}]$, we want to make a prediction on the edges that will be present in the graph $G[t_{1},t_{2}]$ and not present in $G[t_{0},t_{1}]$~\cite{Liben-Nowell}.
%
We denote as training set and test set, the set of edges of $G$ after the training interval and test interval, respectively. The training set is obtained removing the $\alpha\%$ of links from the dataset (namely, missing links).

AUC is defined as follows:
%
\begin{equation}
\label{eqn:auc}
AUC=\frac{n_{1}+0.5n_{2}}{n}
\end{equation}
%
where 
$n_{1}$ is the number of times a missing link has a score greater than an inexistent link,
$n_{2}$ is the number of times a missing link has a score equal to an inexistent link and
$n$ is the total number of combination of missing links and inexistent links.

Our experimental framework consists in measuring the AUC for all metric defined in Equations~\eqref{eqn:common-neighbours}--\eqref{eqn:rra-local}, applied to both criminal and not criminal datasets with test ratios $\alpha=10\%$ and $\alpha=15\%$.
%
The application has been deployed a cluster made of three instances of \textit{Amazon EC2 m3.xlarge} mounting a Intel Xoen E5-2670 v2 (Ivy Bridge) processor, 15 GB DDR4 and a general purpose SSD.
%
In particular, we analyze 
(i) a criminal dataset (CRM) collecting 243 wiretrap-records, judgment and arrest warrants \cite{berlusconi2016link}; and
(ii) a business-related dataset (BSN) collecting 321 face-to-face interactions between employees in a IT company \cite{olguin2009sensible}.
%
Notice that, since the evaluated metrics are all local, the considered datasets are all made of a single connected component, so to avoid the distortion in accuracy measurements.
%
In Table~\ref{tab:auc-detection} and \ref{tab:auc-prediction} we list results for link detection and prediction, highlighting the most notable ones for the considered test ratios, e.g. CRM-10 stands for the criminal dataset with test ratio $\alpha=10\%$.
%
\begin{table}[h]
	\centering
	\begin{tabular}{l l l l l}
	\toprule
	\textbf{Metric} & \textbf{CRM-10} & \textbf{CRM-15} & \textbf{BSN-10} & \textbf{BSN-15}\\
	\midrule
		CN   & 68.952 		   & 75.227 		 & \textbf{83.810} & 75.775 \\
		SLT  & 66.306 		   & 72.919 		 & 80.948 		   & 73.628 \\
		JCR  & 66.377 		   & 72.981 		 & 82.403 		   & 75.054 \\
		SRS  & 66.380 		   & 72.985 		 & 82.405 		   & 75.054 \\
		HPI  & 66.795 		   & 73.507 		 & 66.941 		   & 63.126 \\
		HDI  & 66.514 		   & 73.064 		 & 82.618 		   & 75.194 \\
		LHN1 & 66.100 		   & 72.821 		 & 59.623 		   & 60.386 \\
		PA   & \textbf{80.895} & \textbf{80.383} & 82.618 		   & 75.247 \\
		AA   & \textbf{69.204} & 76.282 		 & \textbf{84.351} & \textbf{76.058} \\
		RA   & 69.156 		   & \textbf{76.283} & \textbf{84.435} & \textbf{75.875} \\
		RRA  & 68.784 		   & 76.196 		 & 71.677 		   & 66.472 \\
		BA   & \textbf{69.293} & \textbf{76.477} & 83.728 		   & \textbf{75.745} \\
		RBA  & 68.870 		   & 76.277 		 & 65.133 		   & 65.015 \\
	\bottomrule
	\end{tabular}
	\caption{AUC for link detection.}
	\label{tab:auc-detection}
\end{table}
%
\begin{table}[h]
	\centering
	\begin{tabular}{l l l l l}
	\toprule
	\textbf{Metric} & \textbf{CRM-10} & \textbf{CRM-15} & \textbf{BSN-10} & \textbf{BSN-15}\\
	\midrule
		CN   & \textbf{82.520} & 76.970 		 & \textbf{77.159} & \textbf{75.249} \\
		SLT  & 80.210 		   & 75.150 		 & 74.312 		   & 70.947 \\
		JCR  & 80.191 		   & 75.208 		 & 75.917 		   & 73.485 \\
		SRS  & 80.191 		   & 75.208 		 & 75.917 		   & 73.485 \\
		HPI  & 81.445 		   & 76.001 		 & 63.194 		   & 60.791 \\
		HDI  & 80.210 		   & 75.223 		 & 75.788 		   & 73.631 \\
		LHN1 & 79.890 		   & 75.028 		 & 59.333 		   & 57.635 \\
		PA   & \textbf{83.314} & \textbf{81.655} & 74.987 		   & 74.373 \\
		AA   & 81.745 		   & \textbf{77.593} & \textbf{76.770} & \textbf{75.149} \\
		RA   & 81.702 		   & 77.497 		 & \textbf{76.023} & \textbf{74.697} \\
		RRA  & 81.322 		   & 77.363 		 & 61.993 		   & 63.661 \\
		BA   & \textbf{82.292} & \textbf{77.769} & 73.044 		   & 72.116 \\
		RBA  & 81.781 		   & 77.581 		 & 63.457 		   & 63.364 \\
	\bottomrule
	\end{tabular}
	\caption{AUC for link prediction.}
	\label{tab:auc-prediction}
\end{table}
%
The experimental results show that the performance achieved by the traditionally adopted metrics leveraging our algorithm are coherent with the ones achieved in batch execution\cite{Lu2011}.
%
Furthermore, the results show that our new metrics can reach up to 83\% accuracy in detection, and 82\% accuracy in prediction; thus providing performance that are competitive with the traditionally adopted one both in detection and prediction.



% OLD PART: START
%
%The experimental results show that classical metrics leveraging our streaming algorithm achieve great performance in prediction tasks, while the novel metrics does it in detection.

%\hlr{This happens because ... (commentate i risultati: che effetto ha avuto definire la nuova metrica? in cosa si evince dall'esperimento la difficolta' di eseguire le metriche classiche in modalita DSP (alle volte sembra si comportino bene) quale punto di forza e' nelle vostre metriche? vi e' differenza tra reti criminali e non?) }
%
%In particular, we notice that in prediction some metrics achieve performances clearly distinguishable from others, while in detection they tend to flatten.
%\hlr{mettete bene in evidenza come mai il vostro risultato vale nel caso in cui il sistema sia di tipo DSP; alla luce dei risultati come si sono comportate le metriche in termini di tempi di processamento (nel DSP siete interessati anche a questo per avere un trade off tra accuracy e tempi di calcolo)}

% OLD PART: END